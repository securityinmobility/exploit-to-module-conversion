import itertools
import os
from file_handling import read_file_content, save_content_in_file, FILE_TO_READ_NOT_FOUND
from ai_chat.gpt_prompting import chat_with_gpt
from initial_system_content import load_initial_system_content

THIRD_STEP_CONTINUE_CONDITION="yes"
QUIT_MESSAGE_EXPLOIT_CONVERSION="Quitting the conversion of the exploit."


def read_prompt(direcotry_to_prompts: str, number_of_prompt: int) -> str:
    path_to_prompt_file = os.path.join(direcotry_to_prompts, f"Prompt_{number_of_prompt}.txt")
    prompt = read_file_content(path_to_prompt_file)
    if FILE_TO_READ_NOT_FOUND in prompt:
        return None
    return prompt


def save_response(i: int, response: str, run_folder: str):
    path = run_folder + "\\response" + str(i) + ".txt"
    save_content_in_file(path, response)


def make_run_folder(dorectory_to_prompts: str) -> str:
    for i in itertools.count(1):
        path = dorectory_to_prompts + "\\run" + str(i)
        if not os.path.exists(path):
            os.makedirs(path)
            return path


def check_answer_to_continue(i: int, response: str):
    if i != 3:
        return True
    else:
        first_characters = ""
        try:
            first_characters = response[:10]
        except:
            return False
        return THIRD_STEP_CONTINUE_CONDITION in first_characters.lower()
    

def run_exploit_conversion(directory_of_prompts: str, path_to_exploit_code: str, directory_of_artifacts: str, example_module_path: str):
    INITIAL_SYSTEM_CONTENT = load_initial_system_content(path_to_exploit_code=path_to_exploit_code, directory_of_artifacts=directory_of_artifacts, example_module_path=example_module_path)
    chat_history = [
        {"role": "system", "content": INITIAL_SYSTEM_CONTENT}
    ]

    # folder where all the responses are saved in
    run_folder = make_run_folder(directory_of_prompts)

    # counter to identify which prompt needs to be read next and at which response the programm is
    i=1
    while True:
        prompt = read_prompt(directory_of_prompts, i)
        if (prompt == None):
            # If there are no or no more prompts to read quit the loop
            break

        chat_history.append({"role": "user", "content": prompt})
        print(f"Sending prompt {i}: {prompt}")
        response = chat_with_gpt(chat_history)
        print(f"Received answer to prompt {i}")
        can_send_next_prompt = check_answer_to_continue(i, response[0])
        save_response(i, response[0], run_folder)
        chat_history.append({"role": "assistant", "content": response[0]})

        if not can_send_next_prompt:
            # If the next prompt does not need to be sent (e.g. because of missing artifacts) quit the loop
            print(QUIT_MESSAGE_EXPLOIT_CONVERSION)
            break
        i = i + 1